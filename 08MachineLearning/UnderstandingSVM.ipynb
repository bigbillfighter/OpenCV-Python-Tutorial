{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "requested-compound",
   "metadata": {},
   "source": [
    "## Understanding SVM\n",
    "\n",
    "### Linear Seperable Data\n",
    "![img](./ipyimg/svm_basics.png)\n",
    "If the data which can be described as high dimentional vectors can be classified by a hyperplane, we say they are liner seperable. The optimal hyperplane we want to get is the one which can perfectly classify the classes with maximum margin.<br>\n",
    "When the points in the dataset are all n-dimentional, we can define the hyperplane as $w^T x + b_0 = 0$. $w = [w_1, w_2, .., w_n]$ is n-dimentional, and $b_0$ is a scalar. We make the 2 classes with label -1 an 1. And $w^T +b_0 >1$ when the label is 1, and $w^T+b_0<-1$ when the label is -1. So $t_i(w^T x + b_0) \\geq 1$. The points of 2 classes which are closest to the plane are called as **support vectors**, which are filled in the image above. We alse call the 2 lines passing through support vectors as **support planes**. And we set them as $t_i(w^T x + b_0) = 1$, so their distance to the plane is $\\frac{1}{||w||}$. What we want is to minimize the function $L(w, b_0)$:\n",
    "$$\n",
    "\\min L(w, b_0) = \\frac{1}{2} ||w||^2 subject \\ to \\ t_i(w^T x + b_0) \\geq 1 \\forall i\n",
    "$$\n",
    "I think $\\frac{1}{2}$ here is for the convenience of making derivative.\n",
    "\n",
    "### None-linear seperable\n",
    "If the data is one-dimentional and one class is $x = 3 or -3$, and the other is $o = 1 or -1$. So they are none-linear seperable. But if we set the feature function as $f(x)=(x, x^2)$, so $x=(3, 9) or (-3, 9)$ and $o=(1, 1) or (-1, 1)$. They are linear seperable. So one is not linear seperable in low dimension may be linear seperable in high dimension. And the dimension of weights $w$ will be corresponding higher. The cost function can be slightly changed as:\n",
    "$$\n",
    "\\min ||w||^2 + C(distance \\ of \\ misclassified \\ samples \\ to \\ their \\ correct \\ regions)\n",
    "$$\n",
    "![img2](./ipyimg/svm_basics2.png)\n",
    "\n",
    "The function can be described as:\n",
    "$$\n",
    "\\min L(w, b_0) = ||w||^2 + C \\sum_{i} \\xi_i \\ subject \\ to \\ y_i(w^T x + b_0) \\geq 1-\\xi_I \\ and \\ \\xi_i \\geq 0 \\ \\forall i\n",
    "$$\n",
    "The first $||w||$ is only calculated on support vectors and the $\\xi$ are only those misclassified.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "controversial-auckland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.04\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "SZ = 20\n",
    "bin_n = 16\n",
    "affine_flags = cv.WARP_INVERSE_MAP | cv.INTER_LINEAR\n",
    "\n",
    "def deskew(img):\n",
    "    '''\n",
    "    This function can make skew image be straight still.\n",
    "    :param img: input image\n",
    "    :return: deskewed image\n",
    "    '''\n",
    "    m = cv.moments(img)\n",
    "    if abs(m['mu02']) < 1e-2:\n",
    "        return img.copy()\n",
    "    skew = m['mu11'] / m['mu02']\n",
    "    M = np.float32([[1, skew, -0.5*SZ*skew], [0, 1, 0]])\n",
    "    img = cv.warpAffine(img, M, (SZ, SZ), flags=affine_flags)\n",
    "    return img\n",
    "\n",
    "def hog(img):\n",
    "    gx = cv.Sobel(img, cv.CV_32F, 1, 0)\n",
    "    gy = cv.Sobel(img, cv.CV_32F, 0, 1)\n",
    "    mag, ang = cv.cartToPolar(gx, gy)\n",
    "    # calculate the magnitude and angle, they are the same shape as the image\n",
    "\n",
    "    bins = np.int32(bin_n*ang/(2*np.pi))\n",
    "    bin_cells = (bins[:10, :10], bins[10:, 10:], bins[:10, 10:], bins[10:, 10:])\n",
    "    mag_cells = (mag[:10, :10], mag[10:, :10], mag[:10, 10:], mag[10:, 10:])\n",
    "\n",
    "    # mag_cells well be the weight\n",
    "    hists = [np.bincount(b.ravel(), m.ravel(), bin_n) for b, m in zip(bin_cells, mag_cells)]\n",
    "    hist = np.hstack(hists) # hist(64, )\n",
    "    return hist\n",
    "\n",
    "img = cv.imread(\"../img/digits.png\", 0)\n",
    "if img is None:\n",
    "    raise Exception(\"Image not found!\")\n",
    "\n",
    "cells = [np.hsplit(row, 100) for row in np.vsplit(img, 50)]\n",
    "\n",
    "train_cells = [i[:50] for i in cells]\n",
    "test_cells = [i[50:] for i in cells]\n",
    "\n",
    "deskewed = [list(map(deskew, row)) for row in train_cells] # deskewed(50, 50, 20, 20)\n",
    "hogdata = [list(map(hog, row)) for row in deskewed] # the feature to train\n",
    "trainData = np.float32(hogdata).reshape(-1, 64)\n",
    "responses = np.repeat(np.arange(10), 250)[:, np.newaxis]\n",
    "\n",
    "svm = cv.ml.SVM_create()\n",
    "svm.setKernel(cv.ml.SVM_LINEAR)\n",
    "svm.setType(cv.ml.SVM_C_SVC) # this type gives penalty to misclassified data\n",
    "svm.setC(2.67) # the hyper parameter C\n",
    "svm.setGamma(5.383)\n",
    "# RBF函数作为kernel后， one hyper parameter. The bigger of gamma, the less support vectors.\n",
    "\n",
    "svm.train(trainData, cv.ml.ROW_SAMPLE, responses)\n",
    "# svm.save('../data/svm_data.dat')\n",
    "\n",
    "deskewed = [list(map(deskew, row)) for row in test_cells]\n",
    "hogdata = [list(map(hog, row)) for row in deskewed]\n",
    "testData = np.float32(hogdata).reshape(-1, bin_n*4)\n",
    "result = svm.predict(testData)[1]\n",
    "\n",
    "mask = result==responses\n",
    "correct = np.count_nonzero(mask)*100.0 / result.size\n",
    "\n",
    "print(correct)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
