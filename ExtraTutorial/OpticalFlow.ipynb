{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dense-meeting",
   "metadata": {},
   "source": [
    "## Lucas-Kanade Optical Flow\n",
    "\n",
    "Optical flow describes the movement of points in continuous frames. So we just talk about optical flow in vidoes. And we can use it to track the moving objects. <br>\n",
    "Optical Flow has many applications, like:\n",
    "- Structure from Motion\n",
    "- Video Copmpression\n",
    "- Video Stablization\n",
    "\n",
    "The theory of Optical Flow is built based on 2 assumptions:\n",
    "1. The pixel intensities of an object do not change between consective frams.\n",
    "2. Neighboring pixels have similar motion.\n",
    "\n",
    "From the 2 above assumptions, we can get the convolution:\n",
    "$$\n",
    "I(x, y, t) = I(x+dx, y+dy, t+dt)\n",
    "$$\n",
    "After dividing by $dt$, we can get:\n",
    "$$\n",
    "f_x u+f_y v +f_t = 0\n",
    "$$\n",
    "where:\n",
    "$$\n",
    "f_x = \\frac{\\partial f}{\\partial x}; f_y = \\frac{\\partial f}{\\partial y}\n",
    "$$$$\n",
    "u = \\frac{dx}{dt},v= \\frac{dy}{dt}\n",
    "$$\n",
    "The $f$ here I think is just $I$, but it is ambiguous in the offical tutorial.\n",
    "\n",
    "**Lucas-Kanada Optical Flow**<br>\n",
    "The derivate function has 2 variables but just one equation. So we can't solve. So we has to use the assumptions before.\n",
    "We assume the points in 3x3 window around the point will have the same motion. So we can just adapt the coordinates of the 9 points and get the $f_x, f_y$, and solve the equation. (The method of calculating $f_x, f_y$ wasn't given, and I think is just use a small window to represent the range that the central point can be in the next frame, just like what meanshift does. We just need to find the statistic minimal distance place.) With a fixed window, we can't track objects when the motion is large between 2 consective frames, so we just use pyramids to address the problem. Because the motion will be smaller in small scale images<br>\n",
    "Conclude the derivates of 9 points, we can calculate $u, v$ with Cramer's rule:\n",
    "$$\n",
    "\\begin{bmatrix} u \\\\ v \\end{bmatrix} = \n",
    "\\begin{bmatrix} \n",
    "\\sum_i f_{x_i}^2 & \\sum_i f_{x_i}f_{y_i} \\\\\n",
    "\\sum_i f_{x_i}f_{y_i} & \\sum_i f_{y_i}^2 \\end{bmatrix} \n",
    "\\begin{bmatrix}\n",
    "-\\sum_i f_{x_i} f_{t_i} \\\\ - \\sum_i f_{y_i} f_{t_i} \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "connected-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import argparse\n",
    "\n",
    "img_path = '../img/slow_traffic_small.mp4'\n",
    "\n",
    "cap = cv.VideoCapture(img_path)\n",
    "\n",
    "# params for Shi-Tomasi corner detection\n",
    "featurce_params = dict(maxCorners = 100,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7)\n",
    "\n",
    "# params for lucas-Kanade optical flow\n",
    "lk_params = dict(winSize = (15, 15),\n",
    "                 maxLevel = 2,\n",
    "                 criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.3))\n",
    "\n",
    "color = np.random.randint(0, 256, (100, 3))\n",
    "\n",
    "# Take first frame and find corners in it\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv.cvtColor(old_frame, cv.COLOR_BGR2GRAY)\n",
    "p0 = cv.goodFeaturesToTrack(old_gray, mask=None, **featurce_params)\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "while 1:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # calculate the optical flow\n",
    "    p1, st, err = cv.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "    # select good points\n",
    "    good_new = p1[st==1]\n",
    "    good_old = p0[st==1]\n",
    "\n",
    "    # draw the tracks\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a,b = new.ravel()\n",
    "        c,d = old.ravel()\n",
    "        mask = cv.line(mask, (a, b), (c, d), color[i].tolist(), 2)\n",
    "        frame = cv.circle(frame, (a, b), 5, color[i].tolist(), -1)\n",
    "\n",
    "    img = cv.add(frame, mask)\n",
    "    cv.imshow('frame', img)\n",
    "    k=cv.waitKey(30)&0xff\n",
    "    if k==27:\n",
    "        break\n",
    "\n",
    "    # Now update the previous frames and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-finland",
   "metadata": {},
   "source": [
    "We can use Dense Optical Flow to computes the optical flow for all the points in the frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "based-spirituality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "cap = cv.VideoCapture('../img/vtest.avi')\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv.cvtColor(frame1,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[..., 1] = 255\n",
    "\n",
    "while 1:\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    next = cv.cvtColor(frame2, cv.COLOR_BGR2GRAY)\n",
    "    flow = cv.calcOpticalFlowFarneback(prvs, next, None, pyr_scale=0.5, levels=3, winsize=15,\n",
    "                                       iterations=3, poly_n=5, poly_sigma=1.2, flags=0)\n",
    "    mag, ang = cv.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "\n",
    "    hsv[..., 0] = ang * 180 /(2*np.pi)\n",
    "    hsv[..., 2] = cv.normalize(mag, None, 0, 255, cv.NORM_MINMAX)\n",
    "    bgr = cv.cvtColor(hsv, cv.COLOR_HSV2BGR)\n",
    "\n",
    "    frame = np.hstack((frame2, bgr))\n",
    "    cv.imshow('frame2', frame)\n",
    "\n",
    "    k = cv.waitKey(30) & 0xff\n",
    "    if k==27:\n",
    "        break\n",
    "\n",
    "    prvs = next\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
